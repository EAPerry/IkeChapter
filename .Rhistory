## Importing Packages and Setup ------------------------------------------------
#:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
# Basic data manipulation and importing
library(tidyverse)
library(lubridate)
library(arrow)
library(fastDummies)
library(callr)
# Spatial
library(sf)
library(tidycensus)
library(tmap)
library(tmaptools)
# Estimation
library(estimatr)
library(plm)
# Aesthetics
library(stargazer)
library(ggpubr)
library(NatParksPalettes)
options(scipen = 9)    # Get rid of scientific notation
#:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
main_df <- read_csv("Results/cleaned_filtered_data.csv")
View(main_df)
main_df %>% filter(year == 2007) %>% group_by(treatment) %>% summarise(cont = sum(CONT))
main_df %>% filter(year == 2007) %>% group_by(treatment) %>% summarise(cont = sum(CONT))
#:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
# Natural Disasters and Giving: Book Chapter -----------------------------------
#:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
#
# Contributor(s): Brenna Jungers, Evan Perry, Drew Westberg
# Last Revised: 2023-04-02
#
# Purpose: The purpose of this script is to clean, organize, and summarize key
# data related to the impact of natural disasters on local charitable giving.
# Primary goals include: (1) basic data cleaning on nonprofit data, (2)
# summarizing and visualizing the data, and (3) running the econometric analysis
# on the data.
#
#
# Input files:
#
# nccs.csv : Consolidated data from NCCS. Raw data from NCCS is too large to
#     upload to GitHub, so this is the consolidated data.
#
# 2020_Planning_Data.csv : County-level census data from the 2010 decennial
#     Census and the 2014 American Community Survey. Use selected variables for
#     perspective on demographic makeup of counties.
#
# co-est2009-alldata.csv : County-level annual population estimates from 2000 -
#     2009.
#
# co-est2019-alldata.csv : County-level annual population estimates from 2010 -
#     2019.
#
# sf12010countydistance500miles.csv : This file contains the distances of every
#     pair of counties that are within 500 miles of each other.
#
# FEMA_Disasters.csv : All disaster declaration records at the county level from
#     FEMA.
#
# hurricanes.csv : A hand-cleaned file that lists the disaster numbers for all
#     relevant hurricanes.
#
#
# Output files:
#
# cleaned_data.csv : Cleaned data incorporating the data listed above. This
#     is panel data with each observation representing a county-year.
#
# summary_stats.tex : Descriptive statistics table.
#
# All the LaTeX tables in the Results/Regression Tables subdirectory.
# All the figures in the Results/Figures subdirectory.
# All the figures in the Results/Robustness Checks subdirectory.
#
# Outline: (Crtl + Shift + O in RStudio)
#   1. Code to Change When Replicating
#   2. Importing Packages and Setup
#   3. Reading and Processing Data
#   4. Data Summary & Visualization
#   5. Analysis
#   6. Placebo Tests
#
#:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
#:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
## Code to Change When Replicating ---------------------------------------------
#:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
# Set your working directory
#setwd("C:/Users/eaper/CoeRA/IkeChapter") #not needed - tied to Rproj.
#:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
#:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
## Importing Packages and Setup ------------------------------------------------
#:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
# Basic data manipulation and importing
library(tidyverse)
library(lubridate)
library(arrow)
library(fastDummies)
library(callr)
# Spatial
library(sf)
library(tidycensus)
library(tmap)
library(tmaptools)
# Estimation
library(estimatr)
library(plm)
# Aesthetics
library(stargazer)
library(ggpubr)
library(NatParksPalettes)
options(scipen = 9)    # Get rid of scientific notation
#:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
disasters <- read_csv("Data/FEMA_Disasters.csv")
disasters_ts <- disasters %>%
filter(
declarationType == "DR",
fyDeclared < 2022,
) %>%
distinct(disasterNumber, .keep_all = T) %>%
count(fyDeclared)
png("Results/Figures/major_disasters.png", width=7, height=4, units="in",res=600)
v <- ggplot(disasters_ts, aes(x = fyDeclared, y = n)) +
geom_line(lwd=1.25, color = natparks.pals("Yellowstone", 1)) +
geom_point(color="white", size=4) +
geom_point(color = natparks.pals("Yellowstone", 1), size = 3) +
labs(x="\nFiscal Year of Declaration", y="# of Major Disaster Declarations\n") +
theme_bw()
print(v)
dev.off()
rm(disasters, disasters_ts)
disasters <- read_csv("Data/FEMA_Disasters.csv")
disasters_ts <- disasters %>%
filter(
declarationType == "DR",
fyDeclared < 2022,
) %>%
distinct(disasterNumber, .keep_all = T) %>%
count(fyDeclared)
View(disasters_ts)
#:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
# Natural Disasters and Giving: Book Chapter -----------------------------------
#:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
#
# Contributor(s): Brenna Jungers, Evan Perry, Drew Westberg
# Last Revised: 2023-04-02
#
# Purpose: The purpose of this script is to clean, organize, and summarize key
# data related to the impact of natural disasters on local charitable giving.
# Primary goals include: (1) basic data cleaning on nonprofit data, (2)
# summarizing and visualizing the data, and (3) running the econometric analysis
# on the data.
#
#
# Input files:
#
# nccs.csv : Consolidated data from NCCS. Raw data from NCCS is too large to
#     upload to GitHub, so this is the consolidated data.
#
# 2020_Planning_Data.csv : County-level census data from the 2010 decennial
#     Census and the 2014 American Community Survey. Use selected variables for
#     perspective on demographic makeup of counties.
#
# co-est2009-alldata.csv : County-level annual population estimates from 2000 -
#     2009.
#
# co-est2019-alldata.csv : County-level annual population estimates from 2010 -
#     2019.
#
# sf12010countydistance500miles.csv : This file contains the distances of every
#     pair of counties that are within 500 miles of each other.
#
# FEMA_Disasters.csv : All disaster declaration records at the county level from
#     FEMA.
#
# hurricanes.csv : A hand-cleaned file that lists the disaster numbers for all
#     relevant hurricanes.
#
#
# Output files:
#
# cleaned_data.csv : Cleaned data incorporating the data listed above. This
#     is panel data with each observation representing a county-year.
#
# summary_stats.tex : Descriptive statistics table.
#
# All the LaTeX tables in the Results/Regression Tables subdirectory.
# All the figures in the Results/Figures subdirectory.
# All the figures in the Results/Robustness Checks subdirectory.
#
# Outline: (Crtl + Shift + O in RStudio)
#   1. Code to Change When Replicating
#   2. Importing Packages and Setup
#   3. Reading and Processing Data
#   4. Data Summary & Visualization
#   5. Analysis
#   6. Placebo Tests
#
#:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
#:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
## Code to Change When Replicating ---------------------------------------------
#:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
# Set your working directory
#setwd("C:/Users/eaper/CoeRA/IkeChapter") #not needed - tied to Rproj.
#:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
#:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
## Importing Packages and Setup ------------------------------------------------
#:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
# Basic data manipulation and importing
library(tidyverse)
library(lubridate)
library(arrow)
library(fastDummies)
library(callr)
# Spatial
library(sf)
library(tidycensus)
library(tmap)
library(tmaptools)
# Estimation
library(estimatr)
library(plm)
# Aesthetics
library(stargazer)
library(ggpubr)
library(NatParksPalettes)
options(scipen = 9)    # Get rid of scientific notation
#:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
library(tidyverse)
library(lubridate)
library(arrow)
library(fastDummies)
library(callr)
# Spatial
library(sf)
library(tidycensus)
library(tmap)
library(tmaptools)
# Estimation
library(fixest)
library(marginaleffects)
# Aesthetics
library(stargazer)
library(ggpubr)
library(NatParksPalettes)
rm(list = ls())
#Load packages
# library(pacman)
# p_load(tidyverse, sandwich, lmtest, fastDummies, stargazer, margins, readr,
#        NatParksPalettes, ggpubr, install = F)
# # Write a function to make the standard errors
# do_the_SE <- function(model){
#   # Cluster the SEs
#   se <- data.frame(summary(model, cluster = "FIPS")$coefficients)$`Std..Error`
#
#   # Fix the position problem
#   temp <- which(summary(model)[["aliased"]])
#
#   for (i in 1:length(temp)){se <- append(se, 1, after=temp[i]-1)}
#   return(se)
# }
#
#
# Read in data
df <- read_csv('Results/cleaned_filtered_data.csv')
#:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
#Update yvars for final outputs
yvars <- c("output", "density")
# # Run regressions for each of the outcome variables in "yvars"
# firstModels <- lapply(yvars, function(x){
#   lm(formula =
#        paste0("log(`", x, "`) ~ treatment*post + as.factor(year) + as.factor(FIPS)"),
#      data = df)
# })
#
# firstModels[[length(firstModels)+1]] <-
#   lm(dependence ~ treatment*post + as.factor(year) + as.factor(FIPS),
#      data = df)
#
# names(firstModels) <- c(yvars, "dependence") #label ea. regression by yvar
#
#
#
# # Store clustered SEs
# firstSE <- lapply(firstModels, do_the_SE)
#
# #Save regression table
# stargazer(firstModels,
#           title = "Preliminary Difference-in-Differences",
#           omit = c("factor","Constant"),
#           se = firstSE,
#           type = "latex",
#           order = c(
#             "treatment:post",
#             "treatment",
#             "post"
#           ),
#           font.size = 'small',
#           covariate.labels = c(
#             "Disaster * Post Storm",
#             "Disaster",
#             "Post Storm"
#           ),
#           dep.var.labels.include = F,
#           column.labels = c(yvars, "dependence"),
#           omit.stat = c("rsq", "adj.rsq"),
#           out = "Results/Regression Tables/blj_reg1.tex")
#
# #:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
#
#
# #:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
#
# # Run regressions for each of the outcome variables in "yvars"
# secondModels <- lapply(yvars, function(x){
#   lm(formula =
#        paste0("log(`", x, "`) ~ treatment:post:log(fixedcont) + treatment*post +
#               log(fixedcont) + as.factor(year) + as.factor(FIPS)"),
#      data = df[is.finite(log(df$fixedcont)),])
# })
#
# secondModels[[length(secondModels)+1]] <- lm(
#   dependence ~ treatment:post:log(fixedcont) + treatment*post + log(fixedcont) +
#     as.factor(year) + as.factor(FIPS),
#   data = df[is.finite(log(df$fixedcont)),])
#
# names(secondModels) <- c(yvars, "dependence") #label ea. regression by yvar
#
# # Store clustered SEs
# secondSE <- lapply(secondModels, do_the_SE)
#
# #Save regression table
# stargazer(secondModels,
#           title = "Heterogeneous Effects Through Pre-Disaster Contributions",
#           omit = c("factor","Constant"),
#           se = secondSE,
#           type = "latex",
#           order = c(
#             "treatment:post:log(fixedcont)",
#             "treatment:post",
#             "treatment",
#             "post",
#             "log(fixedcont)"
#           ),
#           font.size = 'small',
#           covariate.labels = c(
#             "Disaster * Post Storm * Log 2007 Cont.",
#             "Disaster * Post Storm",
#             "Disaster",
#             "Post Storm",
#             "Log 2007 Cont."
#           ),
#           dep.var.labels.include = F,
#           column.labels = c(yvars, "dependence"),
#           omit.stat = c("rsq", "adj.rsq"),
#           out = "Results/Regression Tables/blj_reg2.tex")
#
# #:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
#
#
# #:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
#
# # Run regressions for each of the outcome variables in "yvars"
# thirdModels <- lapply(yvars, function(x){
#   lm(formula =
#        paste0("log(`", x, "`) ~ treatment:post:tpost + treatment*post +
#                tpost + as.factor(year) + as.factor(FIPS)"),
#      data = df)
# })
#
# thirdModels[[length(thirdModels)+1]] <-
#   lm(dependence ~ treatment:post:tpost + treatment*post + tpost +
#        as.factor(year) + as.factor(FIPS), data = df)
#
# names(thirdModels) <- c(yvars, "dependence") #label ea. regression by yvar
#
# # Store clustered SEs
# thirdSE <- lapply(thirdModels, do_the_SE)
#
# #Save regression table
# stargazer(thirdModels,
#           title = "Differences-in-Differences with Dynamic Effects",
#           omit = c("factor","Constant"),
#           se = thirdSE,
#           type = "latex",
#           order = c(
#             "treatment:post:tpost",
#             "treatment:post",
#             "treatment",
#             "post",
#             "tpost"
#           ),
#           font.size = 'small',
#           covariate.labels = c(
#             "Disaster * Post Storm * Years After",
#             "Disaster * Post Storm",
#             "Disaster",
#             "Post Storm",
#             "Years After"
#           ),
#           dep.var.labels.include = F,
#           column.labels = c(yvars, "dependence"),
#           omit.stat = c("rsq", "adj.rsq"),
#           out = "Results/Regression Tables/blj_reg3.tex")
#
# #:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
#
#
#
#:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
# Helper Functions -------------------------------------------------------------
#:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
# Run the regression of choice
my_reg <- function(outcome, rhs, fe, sample_df){
f = as.formula(paste(outcome, '~', rhs, "|", fe))
reg_results = feols(f, sample_df)
return(reg_results)
}
# Make a proper table
my_table <- function(rhs, fe, sample_df, filename, title) {
outcome_list <- list("log_output","log_density","dependence")
all_models <- lapply(outcome_list, function (x) my_reg(x , rhs, fe, sample_df))
unlink(filename)
etable(all_models,
vcov = "hc1",
tex = T,
title = title,
file = filename,
dict = var_labs,
order = c("Disaster", "Post", "log GC"),
adjustbox = "max width = \\textwidth, center"
)
return(all_models)
}
#:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
#:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
# Read in and final data prep --------------------------------------------------
#:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
df <- read_csv('Results/cleaned_filtered_data.csv')
# Give some log transforms to the data (a little treat)
df <- df %>%
mutate(
log_output = log(output),
log_density = log(density),
log_fixedcont = log(fixedcont),
log_pop = log(pop),
ATT = post*treatment              #specify ATT for marginal effects plotting
)
# And make a little data dictionary
var_labs <- c(
`as.factor(year)` = "Year",
`as.factor(FIPS)` = "County",
treatment = "Disaster",
post = "Post",
tpost = "Years Post",
log_fixedcont = "log GC$_{2007}$",
log_output = "log Output",
log_density = "log Density",
dependence = "Dependence",
log_pop = "log Population",
ATT = "average treatment effect on the treated"
)
#:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
#:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
# Basic DiD --------------------------------------------------------------------
#:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
basicdid <- my_table(
rhs = "ATT + post + treatment",
fe = "as.factor(year) + as.factor(FIPS)",
sample_df = df,
filename = "Results/Regression Tables/eap_baseline.tex",
title = "Baseline Difference-in-Differences"
)
summary(basicdid[[1]])
summary(basicdid[1])
intdid <- my_table(
rhs = "ATT:log_fixedcont + ATT + treatment + post + log_fixedcont",
fe = "as.factor(year) + as.factor(FIPS)",
sample_df = df %>% filter(is.finite(log_fixedcont)),
filename = "Results/Regression Tables/eap_thru_2007cont.tex",
title = "Heterogenous Effects Through Contributions"
)
install.packages("tikzDevice")
library(tikzDevice)
plot_slopes(intdid[[1]], variables = "ATT", condition = "log_fixedcont")
install.packages("fixest")
install.packages("fixest")
install.packages("fixest")
install.packages("fixest")
install.packages("fixest")
install.packages("fixest",
repos = c(ropensci = 'https://fastverse.r-universe.dev',
CRAN = 'https://cloud.r-project.org'))
remove.packages("fixest")
install.packages("fixest",
repos = c(ropensci = 'https://fastverse.r-universe.dev',
CRAN = 'https://cloud.r-project.org'))
install.packages("fixest")
install.packages("C:/Users/bj993/Downloads/fixest-0.12.0.zip", repos = NULL, type = "win.binary")
install.packages("Rtools")
install.packages("C:/Users/bj993/Downloads/fixest-0.12.0.zip", repos = NULL, type = "win.binary")
install.packages("remotes")
library(remotes)
remotes::install_github("lrberge/fixest")
install.packages("C:/Users/bj993/Downloads/fixest-0.12.0.zip", repos = NULL, type = "win.binary")
library(fixest-0.12.0)
library(fixest)
install.packages(c("apollo", "arrow", "backports", "bdsmatrix", "bgw", "BH", "bookdown", "boot", "brew", "brio", "broom", "bslib", "cachem", "callr", "checkmate", "classInt", "cli", "cluster", "coda", "codetools", "collapse", "commonmark", "cowplot", "cpp11", "crosstalk", "curl", "data.table", "DBI", "dbplyr", "desc", "DescTools", "digest", "distributional", "dplyr", "e1071", "estimatr", "evaluate", "expm", "fansi", "farver", "fastmap", "foreign", "fs", "future", "geometries", "gert", "ggdist", "ggmap", "ggplot2", "ggrepel", "ggsci", "gh", "globals", "glue", "gtable", "haven", "highr", "htmltools", "htmlwidgets", "httpuv", "httr2", "jsonlite", "KernSmooth", "knitr", "later", "lattice", "leafem", "leaflet", "leaflet.providers", "lifecycle", "listenv", "lme4", "lubridate", "lwgeom", "markdown", "MatrixModels", "matrixStats", "maxLik", "MCMCpack", "mgcv", "minqa", "munsell", "mvtnorm", "nlme", "openintro", "openssl", "parallelly", "pkgbuild", "pkgdown", "pkgload", "plm", "plotly", "plyr", "posterior", "prettyunits", "processx", "progress", "promises", "ps", "quantreg", "ragg", "raster", "rbibutils", "Rcpp", "RcppArmadillo", "RcppEigen", "RCurl", "Rdpack", "readr", "rematch", "reprex", "RgoogleMaps", "rJava", "rlang", "rmarkdown", "rootSolve", "roxygen2", "rpart", "rprojroot", "RSQLite", "rstudioapi", "rvest", "s2", "sandwich", "sass", "scales", "sf", "sfheaders", "shape", "shiny", "snakecase", "snowfall", "sp", "SparseM", "spatial", "stars", "stringi", "stringr", "survival", "systemfonts", "tensorA", "terra", "testthat", "textshaping", "tidyr", "tidyselect", "tigris", "timechange", "tinytex", "tmap", "tmvtnorm", "units", "usdata", "usethis", "utf8", "uuid", "vctrs", "VGAM", "viridis", "vroom", "waldo", "withr", "wk", "xfun", "XML", "xml2", "xopen", "yaml", "zip"))
install.packages(c("apollo", "arrow", "backports", "bdsmatrix", "bgw", "BH", "bookdown", "boot", "brew", "brio", "broom", "bslib", "cachem", "callr", "checkmate", "classInt", "cli", "cluster", "coda", "codetools", "collapse", "commonmark", "cowplot", "cpp11", "crosstalk", "curl", "data.table", "DBI", "dbplyr", "desc", "DescTools", "digest", "distributional", "dplyr", "e1071", "estimatr", "evaluate", "expm", "fansi", "farver", "fastmap", "foreign", "fs", "future", "geometries", "gert", "ggdist", "ggmap", "ggplot2", "ggrepel", "ggsci", "gh", "globals", "glue", "gtable", "haven", "highr", "htmltools", "htmlwidgets", "httpuv", "httr2", "jsonlite", "KernSmooth", "knitr", "later", "lattice", "leafem", "leaflet", "leaflet.providers", "lifecycle", "listenv", "lme4", "lubridate", "lwgeom", "markdown", "MatrixModels", "matrixStats", "maxLik", "MCMCpack", "mgcv", "minqa", "munsell", "mvtnorm", "nlme", "openintro", "openssl", "parallelly", "pkgbuild", "pkgdown", "pkgload", "plm", "plotly", "plyr", "posterior", "prettyunits", "processx", "progress", "promises", "ps", "quantreg", "ragg", "raster", "rbibutils", "Rcpp", "RcppArmadillo", "RcppEigen", "RCurl", "Rdpack", "readr", "rematch", "reprex", "RgoogleMaps", "rJava", "rlang", "rmarkdown", "rootSolve", "roxygen2", "rpart", "rprojroot", "RSQLite", "rstudioapi", "rvest", "s2", "sandwich", "sass", "scales", "sf", "sfheaders", "shape", "shiny", "snakecase", "snowfall", "sp", "SparseM", "spatial", "stars", "stringi", "stringr", "survival", "systemfonts", "tensorA", "terra", "testthat", "textshaping", "tidyr", "tidyselect", "tigris", "timechange", "tinytex", "tmap", "tmvtnorm", "units", "usdata", "usethis", "utf8", "uuid", "vctrs", "VGAM", "viridis", "vroom", "waldo", "withr", "wk", "xfun", "XML", "xml2", "xopen", "yaml", "zip"))
install.packages("C:/Users/bj993/Downloads/fixest-0.12.0.zip", repos = NULL, type = "win.binary")
install.packages("fixest")
